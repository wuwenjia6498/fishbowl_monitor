#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é±¼ç›†è¶‹åŠ¿é›·è¾¾ - ETL æ¯æ—¥æ›´æ–°è„šæœ¬ v7.0 (å¢é‡è¿½åŠ æ¨¡å¼ - Stability Upgrade)
åŠŸèƒ½ï¼š
1. å®½åŸºå¤§åŠ¿ï¼šè·å–åŸç”ŸæŒ‡æ•° + å…¨çƒæŒ‡æ•° + è´µé‡‘å±ç°è´§æ•°æ®
2. è¡Œä¸šè½®åŠ¨ï¼šè·å– ETF æ—¥çº¿æ•°æ® (ä½¿ç”¨ fund_daily + qfq å‰å¤æƒ)
3. å¤šæ¥å£è·¯ç”±ï¼šindex_daily(Aè‚¡) + index_global(å…¨çƒ) + sge_daily(è´µé‡‘å±)
4. è®¡ç®—é±¼ç›†ä¿¡å·ï¼ˆ20æ—¥å‡çº¿ç­–ç•¥ï¼‰
5. æŒ‰ sort_rank æ’åºï¼Œä¿è¯å›ºå®šé¡ºåº
6. åªå¤„ç† is_active=true æˆ– is_system_bench=true çš„èµ„äº§
7. [v5.8] ç”Ÿæˆå…¨æ™¯æˆ˜æœ¯é©¾é©¶èˆ±æ•°æ®ï¼šAè‚¡åŸºå‡†ã€ç¾è‚¡é£å‘ã€é¿é™©èµ„äº§ã€é¢†æ¶¨å…ˆé”‹
8. [NEW v7.0] è¶‹åŠ¿å›¾å¢é‡è¿½åŠ æ¨¡å¼ï¼š
   - ä»æ•°æ®åº“è¯»å–å·²æœ‰ sparkline_json
   - åªè¿½åŠ ä»Šæ—¥æ•°æ®ç‚¹ï¼Œé¿å…æ¯æ—¥å…¨é‡æ‹‰å–å†å²æ•°æ®
   - è‡ªåŠ¨å»é‡ã€æ»‘åŠ¨çª—å£è£å‰ªï¼ˆä¿æŒæœ€è¿‘250å¤©ï¼‰
   - åªåœ¨é¦–æ¬¡åˆå§‹åŒ–æ—¶è°ƒç”¨ Tushare å†å²æ¥å£
   - æå¤§æå‡ç¨³å®šæ€§ï¼Œå‡å°‘å¯¹å¤–éƒ¨ API çš„ä¾èµ–
"""

import os
import sys
import pandas as pd
import tushare as ts
import yfinance as yf  # v6.4: ç”¨äºè·å–å®æ—¶ç¾è‚¡æŒ‡æ•°æ•°æ®
import psycopg2
from psycopg2.extras import RealDictCursor, execute_values
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from dotenv import load_dotenv
import time
import json

# è®¾ç½®æ ‡å‡†è¾“å‡ºç¼–ç ä¸ºUTF-8ï¼ˆè§£å†³Windowsç¼–ç é—®é¢˜ï¼‰
if sys.platform.startswith('win'):
    sys.stdout.reconfigure(encoding='utf-8')

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


# ================================================
# æ•°æ®åº“è¿æ¥ç®¡ç†
# ================================================
class DatabaseConnection:
    """æ•°æ®åº“è¿æ¥ç®¡ç†"""

    def __init__(self):
        base_url = os.getenv('DATABASE_URL')
        if not base_url:
            raise ValueError("ç¯å¢ƒå˜é‡ DATABASE_URL æœªè®¾ç½®")

        # è®¾ç½®æ—¶åŒºä¸ºAsia/Shanghaiï¼Œç¡®ä¿DATEå­—æ®µä¸è¢«æ—¶åŒºè½¬æ¢
        # URLç¼–ç ï¼šç©ºæ ¼=%20, =/=%3D
        if '?' in base_url:
            self.connection_url = f"{base_url}&options=-c%20timezone%3DAsia/Shanghai"
        else:
            self.connection_url = f"{base_url}?options=-c%20timezone%3DAsia/Shanghai"

    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        try:
            return psycopg2.connect(self.connection_url)
        except Exception as e:
            print(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
            raise

    def query_data(self, sql: str, params: tuple = None) -> List[Dict]:
        """æ‰§è¡ŒæŸ¥è¯¢å¹¶è¿”å›æ•°æ®"""
        try:
            conn = self.get_connection()
            cursor = conn.cursor(cursor_factory=RealDictCursor)
            cursor.execute(sql, params)
            results = [dict(row) for row in cursor.fetchall()]
            cursor.close()
            conn.close()
            return results
        except Exception as e:
            print(f"æŸ¥è¯¢æ“ä½œå¤±è´¥: {str(e)}")
            return []

    def get_existing_sparkline(self, symbol: str) -> Optional[str]:
        """
        v7.0: ä»æ•°æ®åº“è·å–æŒ‡å®šæ ‡çš„çš„ç°æœ‰ sparkline_json æ•°æ®

        Args:
            symbol: æ ‡çš„ä»£ç 

        Returns:
            sparkline_json å­—ç¬¦ä¸²ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
        """
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # æŸ¥è¯¢è¯¥æ ‡çš„æœ€æ–°çš„ sparkline_json
            query = """
                SELECT sparkline_json 
                FROM fishbowl_daily 
                WHERE symbol = %s 
                  AND sparkline_json IS NOT NULL
                ORDER BY date DESC 
                LIMIT 1
            """
            cursor.execute(query, (symbol,))
            result = cursor.fetchone()
            
            cursor.close()
            conn.close()
            
            if result and result[0]:
                return result[0]
            return None
            
        except Exception as e:
            print(f"  âš ï¸  è¯»å– {symbol} çš„ sparkline å¤±è´¥: {str(e)}")
            return None


# ================================================
# Tushare æ•°æ®è·å–å™¨
# ================================================
class DataFetcher:
    """æ•°æ®è·å–å™¨ï¼Œä½¿ç”¨Tushare APIè·å–æŒ‡æ•°æ•°æ®"""

    def __init__(self):
        self.token = os.getenv('TUSHARE_TOKEN')
        if not self.token:
            raise ValueError("ç¯å¢ƒå˜é‡ TUSHARE_TOKEN æœªè®¾ç½®")
        ts.set_token(self.token)
        self.pro = ts.pro_api()

    def get_index_daily_data(self, symbol: str, days: int = 365) -> pd.DataFrame:
        """
        è·å–æŒ‡æ•°æ—¥çº¿æ•°æ® (ç”¨äºå®½åŸºæŒ‡æ•°)
        ä½¿ç”¨index_dailyæ¥å£
        """
        try:
            end_date = datetime.now().strftime('%Y%m%d')
            start_date = (datetime.now() - timedelta(days=days)).strftime('%Y%m%d')

            # æŒ‡æ•°æ•°æ®
            df = self.pro.index_daily(ts_code=symbol, start_date=start_date, end_date=end_date)
            time.sleep(0.35)

            if df.empty:
                print(f"  âš ï¸  è­¦å‘Š: æ²¡æœ‰è·å–åˆ°æŒ‡æ•° {symbol} çš„æ•°æ®")
                return pd.DataFrame()

            # æŒ‰æ—¥æœŸå‡åºæ’åˆ—
            df = df.sort_values('trade_date').reset_index(drop=True)
            df['date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d')

            return df[['date', 'close']]

        except Exception as e:
            print(f"  âŒ è·å–æŒ‡æ•° {symbol} æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return pd.DataFrame()

    def get_etf_daily_data(self, symbol: str, days: int = 365) -> pd.DataFrame:
        """
        è·å–ETFæ—¥çº¿æ•°æ®
        ä½¿ç”¨fund_dailyæ¥å£ + å‰å¤æƒ(qfq)æ¶ˆé™¤åˆ†çº¢ç¼ºå£

        Args:
            symbol: ä»£ç ï¼Œæ ¼å¼å¦‚ '512480.SH' (ETF)
            days: è·å–æœ€è¿‘Nå¤©çš„æ•°æ®

        Returns:
            DataFrame åŒ…å«æ—¥æœŸå’Œæ”¶ç›˜ä»·æ•°æ®
        """
        try:
            end_date = datetime.now().strftime('%Y%m%d')
            start_date = (datetime.now() - timedelta(days=days)).strftime('%Y%m%d')

            # æ‰€æœ‰ETFç»Ÿä¸€ä½¿ç”¨fund_dailyæ¥å£ï¼Œå¿…é¡»ä½¿ç”¨å‰å¤æƒ
            df = self.pro.fund_daily(ts_code=symbol, start_date=start_date, end_date=end_date, adj='qfq')
            time.sleep(0.35)

            if df.empty:
                print(f"  âš ï¸  è­¦å‘Š: æ²¡æœ‰è·å–åˆ° {symbol} çš„æ•°æ®")
                return pd.DataFrame()

            # æŒ‰æ—¥æœŸå‡åºæ’åˆ—
            df = df.sort_values('trade_date').reset_index(drop=True)
            df['date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d')

            return df[['date', 'close']]

        except Exception as e:
            print(f"  âŒ è·å– {symbol} æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return pd.DataFrame()

    def get_us_index_data_yfinance(self, symbol: str, days: int = 365) -> pd.DataFrame:
        """
        v6.4: ä½¿ç”¨ yfinance è·å–ç¾è‚¡æŒ‡æ•°æ•°æ®ï¼ˆè§£å†³ Tushare æ•°æ®æ»åé—®é¢˜ï¼‰

        Args:
            symbol: Tushare ä»£ç ï¼ˆå¦‚ IXIC, SPX, DJIï¼‰
            days: è·å–æœ€è¿‘Nå¤©çš„æ•°æ®

        Returns:
            DataFrame åŒ…å«æ—¥æœŸå’Œæ”¶ç›˜ä»·æ•°æ®
        """
        # Tushare ä»£ç æ˜ å°„åˆ° Yahoo Finance ä»£ç 
        symbol_mapping = {
            'IXIC': '^IXIC',   # çº³æ–¯è¾¾å…‹ç»¼åˆæŒ‡æ•°
            'NDX': '^NDX',     # çº³æ–¯è¾¾å…‹100æŒ‡æ•°
            'SPX': '^GSPC',    # æ ‡æ™®500
            'DJI': '^DJI',     # é“ç¼æ–¯å·¥ä¸šå¹³å‡æŒ‡æ•°
        }

        yahoo_symbol = symbol_mapping.get(symbol)
        if not yahoo_symbol:
            print(f"  âš ï¸  æœªæ‰¾åˆ° {symbol} çš„ Yahoo Finance æ˜ å°„")
            return pd.DataFrame()

        try:
            print(f"  ğŸ‡ºğŸ‡¸ ä½¿ç”¨ yfinance è·å–ç¾è‚¡æ•°æ®: {symbol} -> {yahoo_symbol}")

            # è®¡ç®—æ—¥æœŸèŒƒå›´
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)

            # ä½¿ç”¨ yfinance è·å–æ•°æ®
            ticker = yf.Ticker(yahoo_symbol)
            df = ticker.history(start=start_date, end=end_date)

            if df.empty:
                print(f"  âš ï¸  yfinance æœªè¿”å›æ•°æ®: {yahoo_symbol}")
                return pd.DataFrame()

            # æ•°æ®æ¸…æ´—ï¼šè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ ['date', 'close']
            df = df.reset_index()
            df = df.rename(columns={'Date': 'date', 'Close': 'close'})

            # åªä¿ç•™éœ€è¦çš„åˆ—
            df = df[['date', 'close']].copy()

            # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
            df['date'] = pd.to_datetime(df['date'])

            # æŒ‰æ—¥æœŸå‡åºæ’åˆ—
            df = df.sort_values('date').reset_index(drop=True)

            print(f"  âœ“ yfinance æˆåŠŸè·å– {len(df)} æ¡æ•°æ®ï¼Œæœ€æ–°æ—¥æœŸ: {df['date'].iloc[-1].strftime('%Y-%m-%d')}")

            return df

        except Exception as e:
            print(f"  âš ï¸  yfinance è·å–å¤±è´¥: {str(e)}")
            return pd.DataFrame()

    def fetch_history(self, symbol: str, category: str) -> pd.DataFrame:
        """
        å¤šæ¥å£è·¯ç”±ï¼šæ ¹æ®èµ„äº§ç±»å‹è‡ªåŠ¨é€‰æ‹©å¯¹åº”çš„æ•°æ®æ¥å£
        v5.3: æ”¯æŒ Aè‚¡æŒ‡æ•° + å…¨çƒæŒ‡æ•° + è´µé‡‘å±ç°è´§
        v6.4: ç¾è‚¡æŒ‡æ•°ä¼˜å…ˆä½¿ç”¨ yfinanceï¼ˆè§£å†³ Tushare æ•°æ®æ»åé—®é¢˜ï¼‰
        """
        try:
            # 1. è¡Œä¸šè½®åŠ¨ -> åŸºé‡‘æ¥å£ (ETF)
            if category == 'industry':
                return self.get_etf_daily_data(symbol)

            # 2. å®½åŸºå¤§åŠ¿ -> æ··åˆæ¥å£è·¯ç”±
            # A. è´µé‡‘å± (ä»£ç ç‰¹å¾: Au, Ag å¼€å¤´) -> ä¸Šæµ·é‡‘äº¤æ‰€æ¥å£
            if symbol.startswith('Au') or symbol.startswith('Ag'):
                print(f"  ğŸ”¸ ä½¿ç”¨è´µé‡‘å±æ¥å£: {symbol}")
                df = self.pro.sge_daily(ts_code=symbol)
                time.sleep(0.35)

            # B. ç¾è‚¡æŒ‡æ•° -> ä¼˜å…ˆä½¿ç”¨ yfinanceï¼Œå¤±è´¥æ—¶å›é€€åˆ° Tushare
            elif symbol in ['IXIC', 'SPX', 'DJI', 'NDX']:
                # å°è¯•ä½¿ç”¨ yfinanceï¼ˆå®æ—¶æ•°æ®ï¼‰
                df = self.get_us_index_data_yfinance(symbol)

                # å¦‚æœ yfinance å¤±è´¥ï¼Œå›é€€åˆ° Tushareï¼ˆå¯èƒ½æ»åï¼‰
                # v6.5 æ³¨æ„: NDX (çº³æŒ‡100) Tushare ä¸æ”¯æŒï¼Œåªèƒ½ä¾èµ– yfinance
                if df.empty:
                    # NDX ä¸æ”¯æŒ Tushare å›é€€ï¼ˆTushare åªæœ‰ IXIC ç»¼åˆæŒ‡æ•°ï¼‰
                    if symbol == 'NDX':
                        print(f"  âš ï¸  yfinance å¤±è´¥ä¸” Tushare ä¸æ”¯æŒ {symbol}ï¼Œè·³è¿‡æœ¬æ¬¡æ›´æ–°")
                        return pd.DataFrame()

                    # å…¶ä»–ç¾è‚¡æŒ‡æ•°å¯ä»¥å›é€€åˆ° Tushare
                    print(f"  ğŸ”„ yfinance å¤±è´¥ï¼Œå›é€€åˆ° Tushare æ¥å£: {symbol}")
                    df = self.pro.index_global(ts_code=symbol)
                    time.sleep(0.35)

                    # å¯¹äº Tushare æ•°æ®ï¼Œéœ€è¦è¿›è¡Œæ ¼å¼è½¬æ¢
                    if not df.empty:
                        if 'trade_date' in df.columns:
                            df = df.rename(columns={'trade_date': 'date'})
                        df['date'] = pd.to_datetime(df['date'])
                        df['close'] = pd.to_numeric(df['close'])
                        df = df.sort_values('date').reset_index(drop=True)
                        df = df[['date', 'close']]

                # yfinance æˆåŠŸï¼Œç›´æ¥è¿”å›ï¼ˆå·²ç»æ˜¯æ ‡å‡†æ ¼å¼ï¼‰
                else:
                    return df

            # C. å…¶ä»–å…¨çƒæŒ‡æ•°ï¼ˆæ¸¯è‚¡ç­‰ï¼‰-> Tushare å…¨çƒæŒ‡æ•°æ¥å£
            elif symbol in ['HSI', 'HKTECH']:
                print(f"  ğŸŒ ä½¿ç”¨å…¨çƒæŒ‡æ•°æ¥å£: {symbol}")
                df = self.pro.index_global(ts_code=symbol)
                time.sleep(0.35)

            # D. Aè‚¡æŒ‡æ•° (ä»£ç ç‰¹å¾: æ•°å­—å¼€å¤´) -> Aè‚¡æŒ‡æ•°æ¥å£
            else:
                print(f"  ğŸ‡¨ğŸ‡³ ä½¿ç”¨Aè‚¡æŒ‡æ•°æ¥å£: {symbol}")
                df = self.pro.index_daily(ts_code=symbol)
                time.sleep(0.35)

            # --- æ•°æ®æ¸…æ´—æ ‡å‡†åŒ– (Normalization) ---
            # å¿…é¡»ç¡®ä¿è¿”å›çš„ DataFrame åŒ…å«ä¸”ä»…åŒ…å«: ['date', 'close'] ä¸”æŒ‰æ—¥æœŸå‡åº
            if df.empty:
                print(f"  âš ï¸  è­¦å‘Š: æ²¡æœ‰è·å–åˆ° {symbol} çš„æ•°æ®")
                return pd.DataFrame()

            # ç»Ÿä¸€åˆ—å (Tushare ä¸åŒæ¥å£è¿”å›çš„æ—¥æœŸåˆ—åå¯èƒ½ä¸åŒ)
            if 'trade_date' in df.columns:
                df = df.rename(columns={'trade_date': 'date'})

            # æ ¼å¼è½¬æ¢
            df['date'] = pd.to_datetime(df['date'])
            df['close'] = pd.to_numeric(df['close'])
            df = df.sort_values('date').reset_index(drop=True)

            return df[['date', 'close']]

        except Exception as e:
            print(f"  âŒ è·å– {symbol} æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return pd.DataFrame()


# ================================================
# é±¼ç›†è¶‹åŠ¿è®¡ç®—å™¨
# ================================================
class FishbowlCalculator:
    """é±¼ç›†è¶‹åŠ¿è®¡ç®—å™¨ï¼Œå®ç°20æ—¥å‡çº¿ç­–ç•¥"""

    @staticmethod
    def calculate_all_metrics(df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—æ‰€æœ‰é±¼ç›†æŒ‡æ ‡ï¼šMA20ã€çŠ¶æ€ã€åç¦»åº¦ã€æŒç»­å¤©æ•°ã€ä¿¡å·æ ‡ç­¾
        """
        if df.empty:
            return df

        df = df.copy()

        # 1. è®¡ç®—MA20
        df['ma20_price'] = df['close'].rolling(window=20, min_periods=1).mean()

        # 2. è®¡ç®—çŠ¶æ€ (v6.3 System Audit: å®ç°ä¸¥æ ¼çš„ Â±1% ç¼“å†²å¸¦é€»è¾‘)
        # Rule of Truth (The Constitution):
        # - Close > MA20 * 1.01 â†’ YES (çªç ´ç¼“å†²å¸¦ä¸Šæ²¿)
        # - Close < MA20 * 0.99 â†’ NO  (è·Œç ´ç¼“å†²å¸¦ä¸‹æ²¿)
        # - åœ¨ Â±1% åŒºé—´å†…   â†’ ç»´æŒæ˜¨æ—¥çŠ¶æ€ (é˜²æ­¢éœ‡è¡)
        # - ç¬¬ä¸€å¤©æ— å†å²çŠ¶æ€æ—¶: Close >= MA20 â†’ YES, å¦åˆ™ â†’ NO
        statuses = []
        durations = []

        for i in range(len(df)):
            close = df.loc[i, 'close']
            ma20 = df.loc[i, 'ma20_price']

            # è®¡ç®—ç¼“å†²å¸¦è¾¹ç•Œ
            upper_band = ma20 * 1.01  # ä¸Šæ²¿: MA20 + 1%
            lower_band = ma20 * 0.99  # ä¸‹æ²¿: MA20 - 1%

            if i == 0:
                # ç¬¬ä¸€å¤©åˆå§‹åŒ–ï¼šæ— å†å²çŠ¶æ€ï¼Œç®€å•åˆ¤æ–­
                status = 'YES' if close >= ma20 else 'NO'
                duration = 1
            else:
                prev_status = statuses[-1]
                prev_duration = durations[-1]

                # åº”ç”¨ç¼“å†²å¸¦é€»è¾‘
                if close > upper_band:
                    # çªç ´ä¸Šæ²¿ â†’ å¼ºåˆ¶å¤šå¤´
                    status = 'YES'
                elif close < lower_band:
                    # è·Œç ´ä¸‹æ²¿ â†’ å¼ºåˆ¶ç©ºå¤´
                    status = 'NO'
                else:
                    # åœ¨ç¼“å†²å¸¦å†… â†’ ç»´æŒæ˜¨æ—¥çŠ¶æ€ï¼ˆé˜²éœ‡è¡ï¼‰
                    status = prev_status

                # è®¡ç®—æŒç»­å¤©æ•°
                duration = 1 if prev_status != status else prev_duration + 1

            statuses.append(status)
            durations.append(duration)

        df['status'] = statuses
        df['duration_days'] = durations

        # 3. è®¡ç®—åç¦»åº¦
        df['deviation_pct'] = (df['close'] - df['ma20_price']) / df['ma20_price']

        # 4. è®¡ç®—å½“æ—¥æ¶¨å¹… (change_pct)
        df['change_pct'] = df['close'].pct_change()

        # 5. è®¡ç®—åŒºé—´æ¶¨å¹… (trend_pct) - ä»å½“å‰çŠ¶æ€èµ·å§‹ç‚¹åˆ°ç°åœ¨çš„æ¶¨å¹…
        trend_pcts = []
        for i in range(len(df)):
            duration = df.loc[i, 'duration_days']
            current_close = df.loc[i, 'close']

            # å›æº¯åˆ°çŠ¶æ€èµ·å§‹ç‚¹çš„å‰ä¸€å¤©ï¼ˆå˜ç›˜å‰ä¸€å¤©ï¼‰
            # duration=1 è¡¨ç¤ºä»Šå¤©æ˜¯ç¬¬1å¤©ï¼Œåº”è¯¥ç”¨æ˜¨å¤©çš„ä»·æ ¼ä½œä¸ºåŸºå‡†
            start_index = i - duration

            if start_index >= 0:
                # å¯ä»¥è¿½æº¯åˆ°èµ·å§‹ç‚¹å‰ä¸€å¤©
                start_price = df.loc[start_index, 'close']
                trend_pct = (current_close - start_price) / start_price
            else:
                # æ— æ³•è¿½æº¯ï¼ˆæ•°æ®ä¸å¤Ÿï¼‰ï¼Œè®¾ä¸º None
                trend_pct = None

            trend_pcts.append(trend_pct)

        df['trend_pct'] = trend_pcts

        # 6. ç”Ÿæˆä¿¡å·æ ‡ç­¾
        # v6.1 Bugä¿®å¤ï¼šä¿¡å·æ ‡ç­¾å¿…é¡»ä¸¥æ ¼åŸºäºå½“å‰åç¦»åº¦ï¼Œè€Œä¸æ˜¯status
        # Rule of Truth: deviation > 0 -> å¤šå¤´ä¿¡å·, deviation < 0 -> ç©ºå¤´ä¿¡å·
        signal_tags = []
        for _, row in df.iterrows():
            status = row['status']
            duration = row['duration_days']
            deviation = row['deviation_pct']

            # æ ¸å¿ƒä¿®å¤ï¼šä¿¡å·åˆ¤æ–­å®Œå…¨åŸºäºå½“å‰åç¦»åº¦ï¼Œç¡®ä¿é€»è¾‘ä¸€è‡´æ€§
            if deviation > 0:
                # åç¦»åº¦ä¸ºæ­£ -> å¤šå¤´ä¿¡å·
                if duration <= 3 and status == 'YES':
                    tag = 'BREAKOUT'  # å¯åŠ¨ï¼ˆåˆšçªç ´ä¸”æŒç»­å¤©æ•°çŸ­ï¼‰
                elif deviation > 0.15:
                    tag = 'OVERHEAT'  # è¿‡çƒ­ï¼ˆåç¦»åº¦>15%ï¼‰
                else:
                    tag = 'STRONG'    # ä¸»å‡ï¼ˆç¨³å¥ä¸Šæ¶¨ï¼‰
            else:
                # åç¦»åº¦ä¸ºè´Ÿæˆ–é›¶ -> ç©ºå¤´ä¿¡å·
                if deviation < -0.15:
                    tag = 'EXTREME_BEAR'  # è¶…è·Œï¼ˆåç¦»åº¦<-15%ï¼‰
                else:
                    tag = 'SLUMP'         # å¼±åŠ¿ï¼ˆä¸‹è·Œæˆ–éœ‡è¡ï¼‰

            signal_tags.append(tag)

        df['signal_tag'] = signal_tags

        return df

    @staticmethod
    def generate_sparkline_json(df: pd.DataFrame, days: int = 250,
                               today_date: str = None,
                               today_price: float = None,
                               today_ma20: float = None) -> str:
        """
        ç”Ÿæˆè¿‘Nå¤©çš„ Sparkline JSON æ•°æ®ï¼ˆv6.9: æ”¯æŒæ‰‹åŠ¨æ‹¼æ¥ä»Šæ—¥æ•°æ®ï¼‰
        v7.0: è¯¥æ–¹æ³•ä¿ç•™ç”¨äºåˆå§‹åŒ–åœºæ™¯ï¼ˆæ— å†å²æ•°æ®æ—¶ï¼‰

        Args:
            df: å®Œæ•´çš„å†å²æ•°æ® DataFrameï¼ˆå·²è®¡ç®—å¥½ MA20ï¼‰
            days: éœ€è¦çš„å¤©æ•°ï¼ˆé»˜è®¤250å¤©ï¼Œçº¦ä¸€å¹´ï¼‰
            today_date: ä»Šæ—¥æ—¥æœŸå­—ç¬¦ä¸²ï¼ˆå¯é€‰ï¼Œæ ¼å¼ï¼šYYYY-MM-DDï¼‰
            today_price: ä»Šæ—¥æ”¶ç›˜ä»·ï¼ˆå¯é€‰ï¼‰
            today_ma20: ä»Šæ—¥MA20å€¼ï¼ˆå¯é€‰ï¼‰

        Returns:
            JSON å­—ç¬¦ä¸²ï¼Œæ ¼å¼ï¼š[{"date": "2024-12-01", "price": 3000.12, "ma20": 2980.45}, ...]
        """
        if df.empty:
            return json.dumps([])

        # å–æœ€è¿‘ N å¤©çš„æ•°æ®
        recent_df = df.tail(days).copy()

        # æ„å»º sparkline æ•°æ®æ•°ç»„
        sparkline_data = []
        for _, row in recent_df.iterrows():
            # å®Œæ•´æ—¥æœŸæ ¼å¼ YYYY-MM-DD
            date_str = row['date'].strftime('%Y-%m-%d') if hasattr(row['date'], 'strftime') else str(row['date'])
            # v6.3 Bugä¿®å¤ï¼šå¢åŠ ç²¾åº¦åˆ°4ä½å°æ•°ï¼Œé¿å…å°æ•°å€¼æ—¶ç²¾åº¦ä¸¢å¤±å¯¼è‡´åç¦»åº¦è¢«æŠ¹å¹³
            sparkline_data.append({
                "date": date_str,
                "price": round(float(row['close']), 4),      # 4ä½å°æ•°
                "ma20": round(float(row['ma20_price']), 4)  # 4ä½å°æ•°
            })

        # v6.9: æ‰‹åŠ¨æ‹¼æ¥ä»Šæ—¥æ•°æ®ï¼ˆå¦‚æœæä¾›äº†ä»Šæ—¥æ•°æ®ä¸”å†å²æ•°æ®æœªåŒ…å«ä»Šå¤©ï¼‰
        if today_date and today_price is not None and today_ma20 is not None:
            # æ£€æŸ¥å†å²æ•°æ®çš„æœ€åä¸€æ¡æ—¥æœŸ
            if sparkline_data:
                last_date = sparkline_data[-1]['date']
                if last_date != today_date:
                    # å†å²æ•°æ®ä¸åŒ…å«ä»Šå¤©ï¼Œæ‰‹åŠ¨è¿½åŠ 
                    sparkline_data.append({
                        "date": today_date,
                        "price": round(float(today_price), 4),
                        "ma20": round(float(today_ma20), 4)
                    })
            else:
                # å†å²æ•°æ®ä¸ºç©ºï¼Œç›´æ¥æ·»åŠ ä»Šæ—¥æ•°æ®
                sparkline_data.append({
                    "date": today_date,
                    "price": round(float(today_price), 4),
                    "ma20": round(float(today_ma20), 4)
                })

        return json.dumps(sparkline_data)

    @staticmethod
    def append_to_sparkline(current_chart_json: str, today_date: str, 
                           today_price: float, today_ma20: float, 
                           max_days: int = 250) -> str:
        """
        v7.0: å¢é‡è¿½åŠ æ¨¡å¼ - å°†ä»Šæ—¥æ•°æ®è¿½åŠ åˆ°å·²æœ‰çš„ sparkline ä¸­

        æ ¸å¿ƒé€»è¾‘ï¼š
        1. è¯»å–ç°æœ‰æ•°æ®
        2. è¿½åŠ ä»Šæ—¥æ•°æ®ç‚¹ï¼ˆæˆ–æ›´æ–°åŒæ—¥æ•°æ®ï¼‰
        3. å»é‡å¹¶è£å‰ªåˆ°æœ€è¿‘ N å¤©
        4. è¿”å›æ›´æ–°åçš„ JSON

        Args:
            current_chart_json: æ•°æ®åº“ä¸­å·²æœ‰çš„ sparkline JSON å­—ç¬¦ä¸²
            today_date: ä»Šæ—¥æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰
            today_price: ä»Šæ—¥æ”¶ç›˜ä»·
            today_ma20: ä»Šæ—¥ MA20
            max_days: ä¿ç•™çš„æœ€å¤§å¤©æ•°ï¼ˆé»˜è®¤250å¤©ï¼‰

        Returns:
            æ›´æ–°åçš„ JSON å­—ç¬¦ä¸²
        """
        # 1. è§£æç°æœ‰æ•°æ®ï¼ˆå¸¦å¼‚å¸¸ä¿æŠ¤ï¼‰
        try:
            if current_chart_json:
                current_chart = json.loads(current_chart_json)
                if not isinstance(current_chart, list):
                    print(f"  âš ï¸  Sparkline æ ¼å¼é”™è¯¯ï¼ˆéæ•°ç»„ï¼‰ï¼Œé‡ç½®ä¸ºç©º")
                    current_chart = []
            else:
                current_chart = []
        except (json.JSONDecodeError, TypeError) as e:
            print(f"  âš ï¸  Sparkline è§£æå¤±è´¥: {str(e)}ï¼Œé‡ç½®ä¸ºç©º")
            current_chart = []

        # 2. æ„é€ ä»Šæ—¥æ•°æ®ç‚¹
        new_point = {
            "date": today_date,
            "price": round(float(today_price), 4),
            "ma20": round(float(today_ma20), 4)
        }

        # 3. å¢é‡è¿½åŠ ä¸å»é‡
        if current_chart:
            # æ£€æŸ¥æœ€åä¸€ä¸ªç‚¹çš„æ—¥æœŸ
            last_date = current_chart[-1].get('date', '')
            
            if last_date == today_date:
                # åŒä¸€å¤©ï¼Œæ›´æ–°ï¼ˆè¦†ç›–ï¼‰æœ€åä¸€ä¸ªç‚¹
                current_chart[-1] = new_point
                print(f"  ğŸ”„ æ›´æ–°åŒæ—¥æ•°æ®: {today_date}")
            else:
                # ä¸åŒå¤©ï¼Œè¿½åŠ æ–°æ•°æ®ç‚¹
                current_chart.append(new_point)
                print(f"  â• è¿½åŠ æ–°æ•°æ®ç‚¹: {today_date}")
        else:
            # ç©ºæ•°ç»„ï¼Œç›´æ¥æ·»åŠ 
            current_chart.append(new_point)
            print(f"  ğŸ†• åˆ›å»ºé¦–ä¸ªæ•°æ®ç‚¹: {today_date}")

        # 4. æ»‘åŠ¨çª—å£è£å‰ªï¼ˆåªä¿ç•™æœ€è¿‘ N å¤©ï¼‰
        final_chart = current_chart[-max_days:]

        # 5. è¿”å› JSON å­—ç¬¦ä¸²
        return json.dumps(final_chart)


# ================================================
# ä¸»ETLæµç¨‹
# ================================================
def process_symbol(symbol: str, name: str, category: str, fetcher: DataFetcher) -> Optional[pd.DataFrame]:
    """
    å¤„ç†å•ä¸ªETF/æŒ‡æ•°ï¼šè·å–æ•°æ® -> è®¡ç®—æŒ‡æ ‡

    Args:
        symbol: ä»£ç 
        name: åç§°
        category: ç±»åˆ« (ç”¨äºåˆ¤æ–­è°ƒç”¨å“ªä¸ªæ¥å£)
        fetcher: æ•°æ®è·å–å™¨

    Returns:
        å®Œæ•´çš„å†å²æ•°æ® DataFrameï¼ˆåŒ…å« sparkline æ‰€éœ€çš„30å¤©æ•°æ®ï¼‰
    """
    try:
        print(f"  å¤„ç†: {name} ({symbol}) [{category}]")

        # ä½¿ç”¨æ–°çš„å¤šæ¥å£è·¯ç”±æ–¹æ³•
        df = fetcher.fetch_history(symbol, category)

        if df.empty:
            return None

        # è®¡ç®—æŒ‡æ ‡
        df = FishbowlCalculator.calculate_all_metrics(df)

        # æ·»åŠ symbolåˆ—
        df['symbol'] = symbol

        # è¿”å›å®Œæ•´æ•°æ®æ¡†ï¼ˆv5.9: ç”¨äºç”Ÿæˆ sparklineï¼‰
        return df

    except Exception as e:
        print(f"  âŒ å¤„ç† {symbol} æ—¶å‡ºé”™: {str(e)}")
        return None


def batch_upsert_daily_data(conn, data_list: List[Dict]):
    """æ‰¹é‡æ’å…¥/æ›´æ–°æ¯æ—¥æ•°æ®ï¼ˆv6.9: sparkline_json éç©ºä¿æŠ¤ï¼‰

    ä½¿ç”¨CAST(%s AS DATE)å¼ºåˆ¶ç±»å‹è½¬æ¢ï¼Œé¿å…æ—¶åŒºé—®é¢˜
    v6.9: å¦‚æœ sparkline_json ä¸º Noneï¼Œåˆ™ä¸æ›´æ–°è¯¥å­—æ®µï¼Œä¿ç•™æ•°æ®åº“ä¸­çš„æ—§æ•°æ®
    """
    if not data_list:
        return

    cursor = conn.cursor()

    # é€æ¡æ’å…¥
    for d in data_list:
        # v6.9: æ ¹æ® sparkline_json æ˜¯å¦æœ‰æ•ˆï¼ŒåŠ¨æ€æ„å»º SQL
        if d.get('sparkline_json') is not None:
            # æœ‰æ•ˆçš„ sparklineï¼Œæ›´æ–°æ‰€æœ‰å­—æ®µï¼ˆåŒ…æ‹¬ sparkline_jsonï¼‰
            insert_query = """
                INSERT INTO fishbowl_daily
                    (date, symbol, close_price, ma20_price, status, deviation_pct, duration_days, signal_tag, change_pct, trend_pct, sparkline_json)
                VALUES
                    (CAST(%s AS DATE), %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (symbol, date)
                DO UPDATE SET
                    close_price = EXCLUDED.close_price,
                    ma20_price = EXCLUDED.ma20_price,
                    status = EXCLUDED.status,
                    deviation_pct = EXCLUDED.deviation_pct,
                    duration_days = EXCLUDED.duration_days,
                    signal_tag = EXCLUDED.signal_tag,
                    change_pct = EXCLUDED.change_pct,
                    trend_pct = EXCLUDED.trend_pct,
                    sparkline_json = EXCLUDED.sparkline_json,
                    created_at = CURRENT_TIMESTAMP
            """
            cursor.execute(insert_query, (
                d['date'],
                d['symbol'],
                d['close_price'],
                d['ma20_price'],
                d['status'],
                d['deviation_pct'],
                d['duration_days'],
                d['signal_tag'],
                d['change_pct'],
                d['trend_pct'],
                d['sparkline_json']
            ))
        else:
            # sparkline æ— æ•ˆæˆ–ç”Ÿæˆå¤±è´¥ï¼Œä¸æ›´æ–° sparkline_json å­—æ®µï¼ˆä¿ç•™æ•°æ®åº“æ—§æ•°æ®ï¼‰
            insert_query = """
                INSERT INTO fishbowl_daily
                    (date, symbol, close_price, ma20_price, status, deviation_pct, duration_days, signal_tag, change_pct, trend_pct)
                VALUES
                    (CAST(%s AS DATE), %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (symbol, date)
                DO UPDATE SET
                    close_price = EXCLUDED.close_price,
                    ma20_price = EXCLUDED.ma20_price,
                    status = EXCLUDED.status,
                    deviation_pct = EXCLUDED.deviation_pct,
                    duration_days = EXCLUDED.duration_days,
                    signal_tag = EXCLUDED.signal_tag,
                    change_pct = EXCLUDED.change_pct,
                    trend_pct = EXCLUDED.trend_pct,
                    created_at = CURRENT_TIMESTAMP
            """
            cursor.execute(insert_query, (
                d['date'],
                d['symbol'],
                d['close_price'],
                d['ma20_price'],
                d['status'],
                d['deviation_pct'],
                d['duration_days'],
                d['signal_tag'],
                d['change_pct'],
                d['trend_pct']
            ))

    conn.commit()
    cursor.close()


def update_sort_rankings(conn, date):
    """æ›´æ–°å›ºå®šæ’åºï¼ˆæŒ‰é…ç½®çš„sort_rankæ’åºï¼‰"""
    cursor = conn.cursor()

    # æŒ‰é…ç½®çš„sort_rankæ›´æ–°trend_rankï¼Œä¿æŒå›ºå®šé¡ºåº
    update_query = """
        UPDATE fishbowl_daily
        SET trend_rank = c.sort_rank
        FROM monitor_config c
        WHERE fishbowl_daily.symbol = c.symbol
          AND fishbowl_daily.date = %s
          AND c.sort_rank IS NOT NULL
    """

    cursor.execute(update_query, (date,))
    conn.commit()
    cursor.close()


# ================================================
# v5.8 å…¨æ™¯æˆ˜æœ¯é©¾é©¶èˆ±æ•°æ®èšåˆ
# ================================================
def update_market_overview(fetcher: DataFetcher, db_conn: DatabaseConnection):
    """
    èšåˆç”Ÿæˆå¸‚åœºæ¦‚è§ˆæ•°æ®ï¼šAè‚¡åŸºå‡†ã€ç¾è‚¡é£å‘ã€é¿é™©èµ„äº§ã€é¢†æ¶¨å…ˆé”‹
    """
    print("\n" + "=" * 60)
    print("ğŸ¯ ç”Ÿæˆå…¨æ™¯æˆ˜æœ¯é©¾é©¶èˆ±æ•°æ®...")
    print("=" * 60)
    
    overview_data = {}
    
    # ========================================
    # 1. Aè‚¡åŸºå‡† (ä¸Šè¯ + æ·±è¯)
    # ========================================
    print("\nğŸ“Š 1/4 è·å– Aè‚¡åŸºå‡†æ•°æ®...")
    try:
        # è·å–ä¸Šè¯å’Œæ·±è¯çš„æœ€æ–°æ•°æ®
        sh_df = fetcher.fetch_history('000001.SH', 'broad')
        sz_df = fetcher.fetch_history('399001.SZ', 'broad')
        
        # è®¡ç®—é±¼ç›†çŠ¶æ€
        if not sh_df.empty:
            sh_df = FishbowlCalculator.calculate_all_metrics(sh_df)
            sh_latest = sh_df.iloc[-1]
            
            # è®¡ç®—5æ—¥å‡é‡ (éœ€è¦è·å–æˆäº¤é‡æ•°æ®)
            sh_vol_df = fetcher.pro.index_daily(ts_code='000001.SH', 
                                                 end_date=datetime.now().strftime('%Y%m%d'))
            time.sleep(0.35)
            if not sh_vol_df.empty:
                sh_vol_df = sh_vol_df.sort_values('trade_date', ascending=False).head(6)
                today_amount = float(sh_vol_df.iloc[0]['amount']) if len(sh_vol_df) > 0 else 0
                ma5_amount = float(sh_vol_df.iloc[1:6]['amount'].mean()) if len(sh_vol_df) >= 6 else today_amount
            else:
                today_amount = 0
                ma5_amount = 1
        
        if not sz_df.empty:
            sz_df = FishbowlCalculator.calculate_all_metrics(sz_df)
            sz_latest = sz_df.iloc[-1]
            
            # è®¡ç®—æ·±è¯æˆäº¤é‡
            sz_vol_df = fetcher.pro.index_daily(ts_code='399001.SZ',
                                                 end_date=datetime.now().strftime('%Y%m%d'))
            time.sleep(0.35)
            if not sz_vol_df.empty:
                sz_vol_df = sz_vol_df.sort_values('trade_date', ascending=False).head(6)
                sz_amount = float(sz_vol_df.iloc[0]['amount']) if len(sz_vol_df) > 0 else 0
            else:
                sz_amount = 0
        
        # æ±‡æ€»ä¸¤å¸‚æˆäº¤é¢
        total_amount = today_amount + sz_amount
        vol_ratio = total_amount / ma5_amount if ma5_amount > 0 else 1.0
        vol_tag = "æ”¾é‡" if vol_ratio > 1.0 else "ç¼©é‡"
        
        overview_data['a_share'] = {
            'sh': {
                'price': float(sh_latest['close']),
                'change': float(sh_latest['change_pct'] * 100) if pd.notna(sh_latest['change_pct']) else 0.0,
                'status': sh_latest['status']
            },
            'sz': {
                'price': float(sz_latest['close']),
                'change': float(sz_latest['change_pct'] * 100) if pd.notna(sz_latest['change_pct']) else 0.0,
                'status': sz_latest['status']
            },
            'volume': {
                'amount': round(total_amount / 100000, 2),  # è½¬æ¢ä¸ºäº¿å…ƒï¼ˆåƒå…ƒé™¤ä»¥10ä¸‡ï¼‰
                'tag': vol_tag,
                'ratio': round(vol_ratio, 2)
            }
        }
        print(f"  âœ“ ä¸Šè¯æŒ‡æ•°: {overview_data['a_share']['sh']['price']:.2f} ({overview_data['a_share']['sh']['change']:+.2f}%)")
        print(f"  âœ“ æ·±è¯æˆæŒ‡: {overview_data['a_share']['sz']['price']:.2f} ({overview_data['a_share']['sz']['change']:+.2f}%)")
        print(f"  âœ“ ä¸¤å¸‚æˆäº¤: {overview_data['a_share']['volume']['amount']:.0f}äº¿ ({vol_tag})")
        
    except Exception as e:
        print(f"  âŒ Aè‚¡åŸºå‡†æ•°æ®è·å–å¤±è´¥: {str(e)}")
        overview_data['a_share'] = None
    
    # ========================================
    # 2. ç¾è‚¡é£å‘ (T-1)
    # ========================================
    print("\nğŸŒ 2/4 è·å–ç¾è‚¡é£å‘æ•°æ®...")
    try:
        us_indices = [
            ('IXIC', 'çº³æ–¯è¾¾å…‹'),
            ('SPX', 'æ ‡æ™®500'),
            ('DJI', 'é“ç¼æ–¯')
        ]
        
        us_data = []
        for symbol, name in us_indices:
            try:
                df = fetcher.pro.index_global(ts_code=symbol)
                time.sleep(0.35)
                
                if not df.empty:
                    df = df.sort_values('trade_date', ascending=False)
                    latest = df.iloc[0]
                    
                    us_data.append({
                        'name': name,
                        'price': float(latest['close']),
                        'change': float(latest['pct_chg']) if 'pct_chg' in latest and pd.notna(latest['pct_chg']) else 0.0
                    })
                    print(f"  âœ“ {name}: {latest['close']:.2f} ({latest.get('pct_chg', 0):+.2f}%)")
            except Exception as e:
                print(f"  âš ï¸  {name} æ•°æ®è·å–å¤±è´¥: {str(e)}")
                us_data.append({'name': name, 'price': 0, 'change': 0})
        
        overview_data['us_share'] = us_data
        
    except Exception as e:
        print(f"  âŒ ç¾è‚¡æ•°æ®è·å–å¤±è´¥: {str(e)}")
        overview_data['us_share'] = []
    
    # ========================================
    # 3. é¿é™©èµ„äº§ (å›½é™…é»„é‡‘ä»·æ ¼)
    # ========================================
    print("\nğŸ¥‡ 3/4 è·å–é»„é‡‘æ•°æ®...")
    try:
        # v7.0.1: ä¼˜å…ˆä½¿ç”¨ Tushare çš„ä¸Šæµ·é‡‘äº¤æ‰€æ•°æ®ï¼ˆç¨³å®šå¯é ï¼‰
        # å¤‡ç”¨æ–¹æ¡ˆï¼šyfinance è·å–å›½é™…é‡‘ä»·
        
        # æ–¹æ¡ˆ1ï¼šä»æ•°æ®åº“è¯»å–å·²æ›´æ–°çš„ä¸Šæµ·é‡‘äº¤æ‰€é»„é‡‘ç°è´§æ•°æ®
        try:
            conn = db_conn.get_connection()
            cursor = conn.cursor()
            
            # è·å–æœ€è¿‘2å¤©çš„Au99.99æ•°æ®ï¼ˆè®¡ç®—æ¶¨è·Œå¹…ï¼‰
            cursor.execute("""
                SELECT date, close_price, change_pct
                FROM fishbowl_daily
                WHERE symbol = 'Au99.99'
                ORDER BY date DESC
                LIMIT 2
            """)
            gold_rows = cursor.fetchall()
            cursor.close()
            conn.close()
            
            if gold_rows and len(gold_rows) >= 1:
                latest = gold_rows[0]
                gold_price = float(latest[1])  # close_price
                price_change = float(latest[2] * 100) if latest[2] else 0.0  # change_pct
                
                overview_data['gold'] = {
                    'name': 'ä¸Šæµ·é‡‘ (CNY)',
                    'price': round(gold_price, 2),
                    'change': round(price_change, 2),
                    'unit': 'Â¥'
                }
                print(f"  âœ… ä¸Šæµ·é‡‘ (CNY): Â¥{gold_price:.2f}/å…‹ ({'+' if price_change >= 0 else ''}{price_change:.2f}%)")
            else:
                raise Exception("æ•°æ®åº“æ— é»„é‡‘æ•°æ®")
                
        except Exception as db_error:
            print(f"  âš ï¸  ä»æ•°æ®åº“è¯»å–é»„é‡‘æ•°æ®å¤±è´¥: {str(db_error)}, å°è¯• yfinance")
            
            # æ–¹æ¡ˆ2ï¼šä½¿ç”¨ yfinance è·å–å›½é™…é‡‘ä»·ï¼ˆå¤‡ç”¨ï¼‰
            import yfinance as yf
            import time as time_module

            try:
                # v7.0.1: å¢åŠ å»¶è¿Ÿåˆ°5ç§’ï¼Œé¿å…APIé™æµï¼ˆä¹‹å‰ç¾è‚¡æ•°æ®ä¹Ÿç”¨äº†yfinanceï¼‰
                print("  â³ ç­‰å¾… 5 ç§’é¿å… API é™æµ...")
                time_module.sleep(5)

                # v6.8 ä¸»è¦æ–¹æ¡ˆï¼šè·å– XAUUSD=X (ä¼¦æ•¦é‡‘ç°è´§) æ•°æ®
                xau = yf.Ticker("XAUUSD=X")
                xau_hist = xau.history(period="5d")  # è·å–æœ€è¿‘5å¤©æ•°æ®

                if not xau_hist.empty and len(xau_hist) >= 2:
                    # è·å–æœ€æ–°äº¤æ˜“æ—¥æ•°æ®å’Œå‰ä¸€æ—¥æ•°æ®
                    latest = xau_hist.iloc[-1]
                    prev = xau_hist.iloc[-2]

                    gold_price = float(latest['Close'])
                    prev_close = float(prev['Close'])

                    # v6.8 ä¿®å¤ï¼šæ­£ç¡®è®¡ç®—æ¶¨è·Œå¹…
                    price_change = ((gold_price - prev_close) / prev_close) * 100

                    # éªŒè¯ä»·æ ¼åˆç†æ€§ (1500-3500ç¾å…ƒ/ç›å¸)
                    if gold_price < 1500 or gold_price > 3500:
                        print(f"  âš ï¸  ä¼¦æ•¦é‡‘ä»·æ ¼å¼‚å¸¸: ${gold_price:.2f}, ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
                        raise Exception("ä»·æ ¼è¶…å‡ºåˆç†èŒƒå›´")

                    overview_data['gold'] = {
                        'name': 'ä¼¦æ•¦é‡‘ (USD)',  # v6.8: æ˜ç¡®æ ‡æ³¨ä¸ºä¼¦æ•¦é‡‘
                        'price': round(gold_price, 2),
                        'change': round(price_change, 2),
                        'unit': '$'
                    }
                    print(f"  âœ… ä¼¦æ•¦é‡‘ (USD): ${gold_price:.2f}/ç›å¸ ({'+' if price_change >= 0 else ''}{price_change:.2f}%)")

                else:
                    raise Exception("ä¼¦æ•¦é‡‘æ•°æ®ä¸è¶³")

            except Exception as xau_error:
                print(f"  âš ï¸  yfinance ä¼¦æ•¦é‡‘è·å–å¤±è´¥: {str(xau_error)}, å°è¯•é»„é‡‘æœŸè´§æ•°æ®")

                # å¤‡ç”¨æ–¹æ¡ˆ1ï¼šä½¿ç”¨é»„é‡‘æœŸè´§ (GC=F) æ•°æ®
                try:
                    time_module.sleep(5)  # v7.0.1: å¢åŠ å»¶è¿Ÿåˆ°5ç§’é¿å…é™æµ
                    gc = yf.Ticker("GC=F")
                    gc_hist = gc.history(period="5d")

                    if not gc_hist.empty and len(gc_hist) >= 2:
                        latest = gc_hist.iloc[-1]
                        prev = gc_hist.iloc[-2]

                        gold_price = float(latest['Close'])
                        prev_close = float(prev['Close'])
                        price_change = ((gold_price - prev_close) / prev_close) * 100

                        overview_data['gold'] = {
                            'name': 'é»„é‡‘æœŸè´§ (COMEX)',
                            'price': round(gold_price, 2),
                            'change': round(price_change, 2),
                            'unit': '$'
                        }
                        print(f"  âœ… é»„é‡‘æœŸè´§: ${gold_price:.2f}/ç›å¸ ({'+' if price_change >= 0 else ''}{price_change:.2f}%)")
                    else:
                        raise Exception("é»„é‡‘æœŸè´§æ•°æ®ä¸è¶³")

                except Exception as gc_error:
                    print(f"  âš ï¸  é»„é‡‘æœŸè´§è·å–å¤±è´¥: {str(gc_error)}, å°è¯• GLD ETF")

                    # å¤‡ç”¨æ–¹æ¡ˆ2ï¼šä½¿ç”¨ GLD ETF æ•°æ®
                    try:
                        time_module.sleep(5)  # v7.0.1: å¢åŠ å»¶è¿Ÿåˆ°5ç§’é¿å…é™æµ
                        gld = yf.Ticker("GLD")
                        gld_hist = gld.history(period="5d")

                        if not gld_hist.empty and len(gld_hist) >= 2:
                            latest = gld_hist.iloc[-1]
                            prev = gld_hist.iloc[-2]

                            gld_price = float(latest['Close'])
                            prev_close = float(prev['Close'])

                            # GLD ä¸é»„é‡‘ä»·æ ¼çš„æ¢ç®—å…³ç³»ï¼ˆçº¦1/10ç›å¸é»„é‡‘ï¼‰
                            conversion_factor = 10.87
                            gold_price = gld_price * conversion_factor

                            # v6.8: åŸºäºæ¢ç®—åçš„é»„é‡‘ä»·æ ¼è®¡ç®—æ¶¨è·Œå¹…
                            prev_gold_price = prev_close * conversion_factor
                            price_change = ((gold_price - prev_gold_price) / prev_gold_price) * 100

                            overview_data['gold'] = {
                                'name': 'é»„é‡‘ (GLD)',
                                'price': round(gold_price, 2),
                                'change': round(price_change, 2),
                                'unit': '$'
                            }
                            print(f"  âœ… é»„é‡‘ (GLD): ${gold_price:.2f}/ç›å¸ ({'+' if price_change >= 0 else ''}{price_change:.2f}%)")
                        else:
                            raise Exception("GLDæ•°æ®ä¸è¶³")

                    except Exception as gld_error:
                        print(f"  âš ï¸  GLDè·å–å¤±è´¥: {str(gld_error)}, ä½¿ç”¨é»˜è®¤å€¼")
                        # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ä¼°ç®—å€¼ï¼ˆæ¶¨è·Œå¹…ä¸º0ï¼‰
                        overview_data['gold'] = {
                            'name': 'å›½é™…é»„é‡‘',
                            'price': 2650.0,  # æ›´æ–°ä¸ºæ›´åˆç†çš„ä¼°ç®—å€¼
                            'change': 0.0,
                            'unit': '$'
                        }

    except Exception as e:
        print(f"  âš ï¸  é»„é‡‘æ•°æ®è·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {str(e)}")
        overview_data['gold'] = {
            'name': 'å›½é™…é»„é‡‘',
            'price': 2650.0,
            'change': 0.0,
            'unit': '$'
        }

    # ========================================
    # 4. é¢†æ¶¨å…ˆé”‹ (Top 3 è¡Œä¸šæ¿å—)
    # ========================================
    print("\nğŸš€ 4/4 è·å–é¢†æ¶¨å…ˆé”‹...")
    try:
        conn = db_conn.get_connection()
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        
        # ä»æ•°æ®åº“è·å–å½“æ—¥æ‰€æœ‰è¡Œä¸šETFæ•°æ®ï¼ŒæŒ‰æ¶¨å¹…é™åº
        query = """
            SELECT 
                c.name,
                c.symbol,
                d.change_pct
            FROM fishbowl_daily d
            JOIN monitor_config c ON d.symbol = c.symbol
            WHERE c.category = 'industry'
              AND d.date = (SELECT MAX(date) FROM fishbowl_daily)
              AND d.change_pct IS NOT NULL
            ORDER BY d.change_pct DESC
            LIMIT 3
        """
        
        cursor.execute(query)
        leaders = cursor.fetchall()
        
        leaders_data = []
        for leader in leaders:
            # æå–ETFä»£ç ï¼ˆå»æ‰åç¼€ï¼‰
            code = leader['symbol'].split('.')[0]
            leaders_data.append({
                'name': leader['name'],
                'change': float(leader['change_pct'] * 100),
                'code': code
            })
            print(f"  âœ“ {leader['name']}: +{leader['change_pct']*100:.2f}% (ä»£ç : {code})")
        
        overview_data['leaders'] = leaders_data
        
        cursor.close()
        conn.close()
        
    except Exception as e:
        print(f"  âŒ é¢†æ¶¨å…ˆé”‹æ•°æ®è·å–å¤±è´¥: {str(e)}")
        overview_data['leaders'] = []
    
    # ========================================
    # 5. å­˜å…¥æ•°æ®åº“
    # ========================================
    print("\nğŸ’¾ ä¿å­˜åˆ°æ•°æ®åº“...")
    try:
        conn = db_conn.get_connection()
        cursor = conn.cursor()
        
        today = datetime.now().date()
        
        upsert_query = """
            INSERT INTO market_overview (date, data, updated_at)
            VALUES (%s, %s, CURRENT_TIMESTAMP)
            ON CONFLICT (date)
            DO UPDATE SET
                data = EXCLUDED.data,
                updated_at = CURRENT_TIMESTAMP
        """
        
        cursor.execute(upsert_query, (today, json.dumps(overview_data, ensure_ascii=False)))
        conn.commit()
        
        cursor.close()
        conn.close()
        
        print(f"  âœ“ å¸‚åœºæ¦‚è§ˆæ•°æ®å·²ä¿å­˜: {today}")
        
    except Exception as e:
        print(f"  âŒ æ•°æ®ä¿å­˜å¤±è´¥: {str(e)}")
    
    print("=" * 60)
    print("âœ… å…¨æ™¯æˆ˜æœ¯é©¾é©¶èˆ±æ•°æ®ç”Ÿæˆå®Œæˆï¼")
    print("=" * 60)


def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    print("=" * 60)
    print("é±¼ç›†è¶‹åŠ¿é›·è¾¾ - ETL æ›´æ–° v7.0 (å¢é‡è¿½åŠ æ¨¡å¼)")
    print("=" * 60)

    try:
        # åˆå§‹åŒ–è¿æ¥
        db_conn = DatabaseConnection()
        fetcher = DataFetcher()

        # è·å–æ‰€æœ‰éœ€è¦æ›´æ–°çš„èµ„äº§ï¼ˆæŒ‰sort_rankæ’åºï¼‰
        query = """
            SELECT symbol, name, category, sort_rank
            FROM monitor_config
            WHERE is_active = true OR is_system_bench = true
            ORDER BY sort_rank ASC, symbol
        """
        assets = db_conn.query_data(query)

        if not assets:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ›´æ–°çš„èµ„äº§")
            return

        print(f"\nâœ“ æ‰¾åˆ° {len(assets)} ä¸ªéœ€è¦æ›´æ–°çš„èµ„äº§")
        print("-" * 60)

        # æ‰¹é‡å¤„ç†
        all_results = []
        success_count = 0

        for asset in assets:
            result_df = process_symbol(asset['symbol'], asset['name'], asset['category'], fetcher)
            if result_df is not None:
                all_results.append(result_df)
                success_count += 1

        if not all_results:
            print("\nâš ï¸  æ²¡æœ‰æˆåŠŸè·å–ä»»ä½•æ•°æ®,å¯èƒ½æ˜¯éäº¤æ˜“æ—¥")
            print("â„¹ï¸  è¿™å±äºæ­£å¸¸æƒ…å†µï¼Œè„šæœ¬å°†æ­£å¸¸é€€å‡º")
            return

        # v7.0: å¢é‡è¿½åŠ æ¨¡å¼ - åªåœ¨æ— å†å²æ•°æ®æ—¶æ‰å…¨é‡æ‹‰å–
        print("\n" + "=" * 60)
        print("ğŸ“ˆ v7.0 å¢é‡è¿½åŠ æ¨¡å¼ï¼šç”Ÿæˆè¶‹åŠ¿å›¾æ•°æ®...")
        print("=" * 60)
        
        data_list = []
        for result_df in all_results:
            if result_df.empty:
                continue

            # åªå–æœ€åä¸€å¤©çš„æ•°æ®
            last_row = result_df.iloc[-1]
            symbol = last_row['symbol']

            # ä½¿ç”¨strftimeç”Ÿæˆå­—ç¬¦ä¸²ï¼Œé¿å…psycopg2æ—¶åŒºè½¬æ¢
            date_str = last_row['date'].strftime('%Y-%m-%d') if hasattr(last_row['date'], 'strftime') else str(last_row['date'])

            # v7.0: æ ¸å¿ƒé€»è¾‘ - å…ˆè¯»å–æ•°æ®åº“å·²æœ‰æ•°æ®ï¼Œå†³å®šå¢é‡è¿˜æ˜¯å…¨é‡
            existing_sparkline = db_conn.get_existing_sparkline(symbol)
            sparkline_to_save = None

            # v7.0.1: æ£€æŸ¥ç°æœ‰æ•°æ®æ˜¯å¦å……è¶³ï¼ˆè‡³å°‘éœ€è¦20ä¸ªç‚¹æ‰æœ‰æ„ä¹‰ï¼‰
            needs_reinit = False
            if existing_sparkline:
                try:
                    existing_data = json.loads(existing_sparkline)
                    if len(existing_data) < 20:
                        print(f"  âš ï¸  [{symbol}] ç°æœ‰æ•°æ®ä»… {len(existing_data)} ä¸ªç‚¹ï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ–")
                        needs_reinit = True
                        existing_sparkline = None  # å¼ºåˆ¶è¿›å…¥å…¨é‡æ¨¡å¼
                except:
                    needs_reinit = True
                    existing_sparkline = None

            if existing_sparkline and not needs_reinit:
                # âœ… å¢é‡æ¨¡å¼ï¼šå·²æœ‰å†å²æ•°æ®ï¼Œåªè¿½åŠ ä»Šæ—¥æ•°æ®ç‚¹
                print(f"  ğŸ“Š [{symbol}] å¢é‡è¿½åŠ æ¨¡å¼")
                try:
                    sparkline_json = FishbowlCalculator.append_to_sparkline(
                        current_chart_json=existing_sparkline,
                        today_date=date_str,
                        today_price=float(last_row['close']),
                        today_ma20=float(last_row['ma20_price']),
                        max_days=250
                    )
                    
                    # éªŒè¯ç”Ÿæˆçš„æ•°æ®
                    sparkline_array = json.loads(sparkline_json)
                    if len(sparkline_array) > 0:
                        sparkline_to_save = sparkline_json
                    else:
                        print(f"  âš ï¸  è¿½åŠ åæ•°æ®ä¸ºç©ºï¼Œä¿ç•™æ—§æ•°æ®")
                        sparkline_to_save = None
                        
                except Exception as e:
                    print(f"  âš ï¸  å¢é‡è¿½åŠ å¤±è´¥: {str(e)}ï¼Œä¿ç•™æ—§æ•°æ®")
                    sparkline_to_save = None
            else:
                # ğŸ†• å…¨é‡æ¨¡å¼ï¼šæ— å†å²æ•°æ®ï¼Œè°ƒç”¨ Tushare åˆå§‹åŒ–
                print(f"  ğŸ”„ [{symbol}] é¦–æ¬¡åˆå§‹åŒ–ï¼Œå…¨é‡æ‹‰å–å†å²æ•°æ®...")
                print(f"      å†å²æ•°æ®æ€»è¡Œæ•°: {len(result_df)}")
                try:
                    sparkline_json = FishbowlCalculator.generate_sparkline_json(
                        result_df,
                        days=250,
                        today_date=date_str,
                        today_price=float(last_row['close']),
                        today_ma20=float(last_row['ma20_price'])
                    )
                    
                    # v7.0: é™ä½åˆå§‹åŒ–è¦æ±‚ - åªè¦æœ‰æ•°æ®å°±ä¿å­˜ï¼ˆä» >1 æ”¹ä¸º >0ï¼‰
                    sparkline_array = json.loads(sparkline_json)
                    if len(sparkline_array) > 0:
                        sparkline_to_save = sparkline_json
                        print(f"  âœ… åˆå§‹åŒ–æˆåŠŸï¼Œç”Ÿæˆ {len(sparkline_array)} ä¸ªæ•°æ®ç‚¹")
                    else:
                        print(f"  âš ï¸  åˆå§‹åŒ–å¤±è´¥ï¼Œæ•°æ®ä¸ºç©º")
                        sparkline_to_save = None
                        
                except (json.JSONDecodeError, TypeError) as e:
                    print(f"  âš ï¸  åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                    sparkline_to_save = None

            data_list.append({
                'date': date_str,  # å­—ç¬¦ä¸²æ ¼å¼ï¼Œé¿å…æ—¶åŒºè½¬æ¢
                'symbol': symbol,
                'close_price': float(last_row['close']),
                'ma20_price': float(last_row['ma20_price']),
                'status': last_row['status'],
                'deviation_pct': float(last_row['deviation_pct']),
                'duration_days': int(last_row['duration_days']),
                'signal_tag': last_row['signal_tag'],
                'change_pct': float(last_row['change_pct']) if pd.notna(last_row['change_pct']) else None,
                'trend_pct': float(last_row['trend_pct']) if pd.notna(last_row['trend_pct']) else None,
                'sparkline_json': sparkline_to_save  # v7.0: å¢é‡è¿½åŠ æˆ–å…¨é‡åˆå§‹åŒ–
            })

        # æ‰¹é‡å…¥åº“
        conn = db_conn.get_connection()
        batch_upsert_daily_data(conn, data_list)
        print(f"\nâœ“ æ‰¹é‡å…¥åº“æˆåŠŸ: {len(data_list)} æ¡è®°å½•")

        # æ›´æ–°å›ºå®šæ’åºï¼ˆä» data_list è·å–æœ€æ–°æ—¥æœŸï¼‰
        latest_date = max(d['date'] for d in data_list)
        update_sort_rankings(conn, latest_date)
        print(f"âœ“ æ›´æ–°å›ºå®šæ’åºå®Œæˆ: {latest_date}")

        conn.close()

        # v5.8 æ–°å¢ï¼šç”Ÿæˆå…¨æ™¯æˆ˜æœ¯é©¾é©¶èˆ±æ•°æ®
        update_market_overview(fetcher, db_conn)

        # è¾“å‡ºæ‘˜è¦
        yes_count = len([d for d in data_list if d['status'] == 'YES'])
        no_count = len([d for d in data_list if d['status'] == 'NO'])

        print("\n" + "=" * 60)
        print("ETL æ›´æ–°å®Œæˆï¼")
        print(f"  - æˆåŠŸå¤„ç†: {success_count}/{len(assets)} ä¸ªèµ„äº§")
        print(f"  - å¤šå¤´ (YES): {yes_count}")
        print(f"  - ç©ºå¤´ (NO): {no_count}")
        print(f"  - æœ€æ–°æ—¥æœŸ: {latest_date}")
        print("=" * 60)

    except Exception as e:
        print(f"\nâŒ ETL æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºéäº¤æ˜“æ—¥æˆ–APIé™åˆ¶ç­‰å¯æ¥å—çš„é”™è¯¯
        error_msg = str(e).lower()
        acceptable_errors = [
            'æ— æ•°æ®', 'no data', 'empty', 'tushare', 'api', 'é™åˆ¶', 'limit',
            'éäº¤æ˜“æ—¥', 'holiday', 'å‘¨æœ«', 'weekend', 'ä¼‘æ¯', 'closed'
        ]
        
        # å¦‚æœé”™è¯¯æ¶ˆæ¯åŒ…å«å¯æ¥å—çš„é”™è¯¯å…³é”®è¯ï¼Œåˆ™æ­£å¸¸é€€å‡º
        if any(err in error_msg for err in acceptable_errors):
            print("â„¹ï¸  å¯èƒ½æ˜¯éäº¤æ˜“æ—¥æˆ–APIé™åˆ¶ï¼Œå±äºæ­£å¸¸æƒ…å†µ")
            exit(0)
        else:
            print("âŒ ä¸¥é‡é”™è¯¯ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®")
            exit(1)


if __name__ == "__main__":
    main()
